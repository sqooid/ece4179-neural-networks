{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://www.dropbox.com/s/vold2f3fm57qp7g/ECE4179_5179_6179_banner.png?dl=1\" alt=\"ECE4179/5179/6179 Banner\" style=\"max-width: 60%;\"/>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "\n",
    "# PyTorch Optimizers\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Welcome to Week 5 of ECE4179/5179/6179! This week, we continue our study of optimization techniques, focusing on those provided by PyTorch. Specifically, we will learn about widely-used methods like Stochastic Gradient Descent (SGD)[1], SGD with momentum, and Adam[2]. These optimizers are essential tools for training deep learning models and are foundational in modern machine learning. Let’s get started and see how these optimizers perform in practice!\n",
    "\n",
    "[1] Bottou, L. (2010). *Large-Scale Machine Learning with Stochastic Gradient Descent*. Proceedings of COMPSTAT, 177-186.  \n",
    "[2] Kingma, D. P., & Ba, J. (2015). *Adam: A Method for Stochastic Optimization*. ICLR'14.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc8da0b8d10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as always, we start by importing the necessary packages\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "\n",
    "# Set random seed\n",
    "RND_SEED = 42\n",
    "np.random.seed(RND_SEED)\n",
    "torch.manual_seed(RND_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following helper functions for visualization purposes in this notebook. These functions will allow us to plot the optimization paths and gain insights into how different optimizers behave during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_camel_back_history(hist_x):\n",
    "    \"\"\"\n",
    "    Plot the camelback function and the history of gradient descent.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the camelback function using a lambda function\n",
    "    f_x = lambda x: 4 * x**2 - 2.1 * x**4 + (1 / 3) * x**6 + x * torch.cos(x)\n",
    "\n",
    "    # Convert the history points to a tensor\n",
    "    hist_x = torch.tensor(hist_x, dtype=torch.float32)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Calculate the function values for each point in the history\n",
    "    hist_f = f_x(hist_x)\n",
    "\n",
    "    # Plot the function first to ensure it is in the background\n",
    "    x = torch.linspace(-2, 2, 100)\n",
    "    plt.plot(x, f_x(x), color=\"blue\", label=\"f(x)\", zorder=1)\n",
    "\n",
    "    # Plot arrows, text labels, and circles to visualize the gradient descent path\n",
    "    for i in range(len(hist_x) - 1):\n",
    "        # Calculate the difference between consecutive points\n",
    "        dx = hist_x[i + 1] - hist_x[i]\n",
    "        dy = hist_f[i + 1] - hist_f[i]\n",
    "\n",
    "        # Annotate the path with arrows showing the direction of descent\n",
    "        plt.annotate(\n",
    "            \"\",\n",
    "            xy=(hist_x[i + 1], hist_f[i + 1]),\n",
    "            xytext=(hist_x[i], hist_f[i]),\n",
    "            arrowprops=dict(\n",
    "                facecolor=\"#FF5F1F\",\n",
    "                edgecolor=\"#EC5800\",\n",
    "                shrink=0,\n",
    "                width=2,\n",
    "                headwidth=8,\n",
    "                headlength=10,\n",
    "            ),\n",
    "            zorder=4,\n",
    "        )\n",
    "\n",
    "    # Scatter plot to mark the points along the descent path\n",
    "    plt.scatter(hist_x, hist_f, c=\"k\", s=50, zorder=5)  # Adding a circle at each point\n",
    "\n",
    "    # Label the axes\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"f(x)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ===================================\n",
    "\n",
    "\n",
    "def plot_ackley(hist_x=None):\n",
    "    \"\"\"\n",
    "    Plot the Ackley function and optionally the trajectory of an optimizer.\n",
    "\n",
    "    Parameters:\n",
    "    - hist_x: Optional. A list of [x, y] coordinates representing the optimization trajectory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the Ackley function using a lambda function\n",
    "    ackley_func = (\n",
    "        lambda v: -20\n",
    "        * torch.exp(-0.2 * torch.sqrt(0.5 * (v[:, 0] ** 2 + v[:, 1] ** 2)))\n",
    "        - torch.exp(\n",
    "            0.5\n",
    "            * (torch.cos(2 * torch.pi * v[:, 0]) + torch.cos(2 * torch.pi * v[:, 1]))\n",
    "        )\n",
    "        + torch.exp(torch.tensor(1.0))\n",
    "        + 20\n",
    "    )\n",
    "\n",
    "    # Grid setup\n",
    "    num_pnts = 100\n",
    "    x = torch.linspace(-5, 5, num_pnts)\n",
    "    y = torch.linspace(-5, 5, num_pnts)\n",
    "    X_grid, Y_grid = torch.meshgrid(x, y, indexing=\"ij\")\n",
    "\n",
    "    v = torch.stack([X_grid.reshape(-1), Y_grid.reshape(-1)], dim=1)\n",
    "    Z = ackley_func(v).reshape(num_pnts, num_pnts)\n",
    "\n",
    "    # Plot the contour plot with the trajectory\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    contour_plot = ax.contourf(X_grid, Y_grid, Z, levels=50, cmap=cm.coolwarm)\n",
    "\n",
    "    if hist_x is not None:\n",
    "        # Plot the trajectory\n",
    "        x_history = [coord[0] for coord in hist_x]\n",
    "        y_history = [coord[1] for coord in hist_x]\n",
    "        for i in range(1, len(x_history)):\n",
    "            ax.annotate(\n",
    "                \"\",\n",
    "                xy=(x_history[i], y_history[i]),\n",
    "                xytext=(x_history[i - 1], y_history[i - 1]),\n",
    "                arrowprops=dict(\n",
    "                    facecolor=\"black\", edgecolor=\"black\", arrowstyle=\"->\", lw=2\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        # Add a green star at the final point\n",
    "        ax.plot(x_history[-1], y_history[-1], \"g*\", markersize=15, label=\"Final Point\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.colorbar(contour_plot, ax=ax, shrink=0.75)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_title(\"Contour Plot of Ackley Function with Trajectory\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation with PyTorch\n",
    "\n",
    "We start understanding PyTorch optimizers by learning about Automatic Differentiation (AD).\n",
    "\n",
    "Consider the function:\n",
    "\n",
    "\\begin{align}\n",
    "f(x) = x^3 - 3x^2 + 2x\\;. \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "What is the derivative of this function at $x=2$? \n",
    "\n",
    "In PyTorch, you can compute the derivative of a variable (or more generally, a computational graph) by following these steps:\n",
    "\n",
    "1. Set the attribute `requires_grad=True` for the variable $x$. This tells PyTorch to track operations on this variable for gradient computation.\n",
    "2. Call the `.backward()` method on the computed value of $f(x)$. This triggers PyTorch's automatic differentiation to compute the gradient of $f(x)$ with respect to $x$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color: #3352FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### <span style=\"color: pink;\">Task #1.</span>  AD basics\n",
    "Use PyTorch to obtain the derivative of $f(x) = x^3 - 3x^2 + 2x$ at $x=2$. \n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f(x) at x = 2.0 is: 2.0\n"
     ]
    }
   ],
   "source": [
    "# Define the input tensor with requires_grad=True\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Define the function\n",
    "f_x = torch.pow(x, 3) - 3 * torch.pow(x, 2) + 2 * x\n",
    "\n",
    "# Compute the derivative using backward()\n",
    "f_x.backward()\n",
    "\n",
    "# Display the gradient\n",
    "print(f\"Gradient of f(x) at x = {x.item()} is: {x.grad.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider $\\mathbf{x} \\in \\mathbb{R}^2$ and $\\mathbf{w} \\in \\mathbb{R}^2$. Let:\n",
    "\n",
    "\\begin{align*}\n",
    "    p = \\sigma(\\mathbf{w}^\\top \\mathbf{x})\\;,\n",
    "\\end{align*}\n",
    "\n",
    "where $\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$ is the sigmoid function. The entropy of $p \\in [0, 1]$, which is a measure of uncertainty, is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "    f(p) = -p \\log(p)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "<div style=\"background-color: #3352FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### <span style=\"color: pink;\">Task #2.</span>  Gradient of the Entropy Function\n",
    "\n",
    "\n",
    "Your task is to obtain $\\nabla_{\\mathbf{x}} f$ and $\\nabla_{\\mathbf{w}} f$ at \n",
    "\\begin{align*}\n",
    "    \\mathbf{x} = \\begin{pmatrix} 1.0 \\\\ 2.0 \\end{pmatrix} \\quad \\text{and} \\quad \n",
    "    \\mathbf{w} = \\begin{pmatrix} 0.5 \\\\ -1.5 \\end{pmatrix}\\;.\n",
    "\\end{align*}\n",
    "\n",
    "Since you already know the BP algorithm, you should be able to solve this task by hand. So, work it out with your tablemates and complete the code below to obtain the solution.\n",
    "</div>\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary style=\"color: yellow; font-weight: bold;\">Hint</summary>\n",
    "\n",
    "Use the chain rule (see the example below):\n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_{\\mathbf{x}} f = \\frac{\\partial f}{\\partial p} \\frac{\\partial p}{\\partial z} \\frac{\\partial z}{\\partial \\mathbf{x}} \n",
    "\\end{align*}\n",
    "\n",
    "Also, note the following partial derivatives:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial }{\\partial z}\\sigma(z) = \\sigma(z)\\big(1 - \\sigma(z)\\big)\\;,\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial }{\\partial \\mathbf{x}} \\mathbf{w}^\\top \\mathbf{x} = \\mathbf{w}\\;,\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial }{\\partial \\mathbf{w}} \\mathbf{w}^\\top \\mathbf{x} = \\mathbf{x}\\;.\n",
    "\\end{align*}\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dx = tensor([ 0.0553, -0.1660])\n",
      "df_dw = tensor([0.1107, 0.2214])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "x = torch.tensor([1.0, 2.0])\n",
    "w = torch.tensor([0.5, -1.5])\n",
    "\n",
    "# Compute the linear term (check the dot product function in the PyTorch documentation)\n",
    "z = torch.dot(w, x)\n",
    "\n",
    "# Apply the sigmoid function to get p (check the sigmoid function in the PyTorch documentation)\n",
    "p = torch.sigmoid(z)\n",
    "\n",
    "# Compute the entropy function\n",
    "f = -p * torch.log(p)\n",
    "\n",
    "# Backward pass\n",
    "dz_dw = x\n",
    "dz_dx = w\n",
    "dp_dz = p * (1 - p)\n",
    "df_dp = -torch.log(p) - 1\n",
    "\n",
    "df_dx = df_dp * dp_dz * dz_dx\n",
    "df_dw = df_dp * dp_dz * dz_dw\n",
    "\n",
    "print(f\"df_dx = {df_dx}\")\n",
    "print(f\"df_dw = {df_dw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #3352FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### <span style=\"color: pink;\">Task #3.</span>  Gradient of the Entropy Function using AD\n",
    "\n",
    "Repeat the previous task but this time with PyTorch's automatic differentiation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inputs\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "w = torch.tensor([0.5, -1.5], requires_grad=True)\n",
    "\n",
    "# Compute the linear term (check the dot product function in the PyTorch documentation)\n",
    "z = torch.dot(w, x)\n",
    "\n",
    "# Apply the sigmoid function to get p (check the sigmoid function in the PyTorch documentation)\n",
    "p = torch.sigmoid(z)\n",
    "\n",
    "# Compute the entropy function\n",
    "f = -p * torch.log(p)\n",
    "\n",
    "# Compute the gradients using the backward() function\n",
    "f.backward()\n",
    "\n",
    "# Print the gradients\n",
    "print(f\"Gradient with respect to x: {x.grad}\")\n",
    "print(f\"Gradient with respect to w: {w.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Optimizers\n",
    "\n",
    "In PyTorch, the `torch.optim` module implements several optimizers. The general workflow for using an optimizer is as follows:\n",
    "\n",
    "1. Define what to optimize (i.e., parameters). To do this, set the `requires_grad=True` attribute for the PyTorch tensor(s) that you want to optimize.\n",
    "2. Define the optimizer by passing the parameters to be optimized and the hyperparameters of the optimizer (e.g., learning rate).\n",
    "3. Compute the objective of the optimization problem (e.g., the loss function).\n",
    "4. Compute the gradients of the objective with respect to the parameters. This is done by calling the `.backward()` method on the computed value of the objective.\n",
    "5. Update the parameters using the `.step()` method of the optimizer.\n",
    "\n",
    "The simplest optimizer is SGD (Stochastic Gradient Descent), which is the stochastic version of the Gradient Descent algorithm. The following code snippet shows how to use the SGD optimizer to minimize the function \\( f(x) = x^2 \\):\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the variable to optimize\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD([x], lr=0.1, momentum=0.0)\n",
    "\n",
    "# Compute the objective\n",
    "f_x = x**2\n",
    "\n",
    "# Compute the gradients\n",
    "f_x.backward()\n",
    "\n",
    "# Update the variable\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "In this example, the optimizer performs one step of the SGD algorithm to minimize the function $f(x) = x^2$ using a learning rate of 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Six-hump Camelback function\n",
    "\n",
    "Let's practice by optimizing our beloved six-hump camelback function defined as:\n",
    "\\begin{align}\n",
    "    f(x) = 4x^2 - 2.1x^4 + \\frac{1}{3}x^6 + x\\cos(x)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://www.nicepng.com/png/detail/245-2450208_camels-clipart-2-hump-cartoon-camel-two-humps.png\" alt=\"cute camel\" style=\"max-width: 40%;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"background-color: #3352FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### <span style=\"color: pink;\">Task #4.</span>  Minimizing the Six-hump Camelback function with SGD\n",
    "\n",
    "SGD optimizer is the stochastic version of the Gradient Descent algorithm. Use the SGD optimizer to minimize the six-hump camelback function. For this task, run the optimizer for 10 iterations, and start from $x=2.0$. Make sure the momentum is set to 0.0.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10 # Keep this as 10 but feel free to change it to see the behaviour\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = SGD([x], \n",
    "                lr=, # <--- YOUR CODE HERE \n",
    "                momentum=0.0) # Keep this as 0.0 in this task\n",
    "\n",
    "def camel_back_func(x):\n",
    "    f_x = # <--- YOUR CODE HERE\n",
    "    return f_x\n",
    "\n",
    "hist_x = []\n",
    "for iter in range(num_iterations):\n",
    "    hist_x.append(x.clone().detach())\n",
    "\n",
    "    # Clear the gradient (this is needed in PyTorch)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute the function\n",
    "    f_x = # <--- YOUR CODE HERE \n",
    "\n",
    "    # Compute the gradient\n",
    "    f_x # <--- YOUR CODE HERE \n",
    "\n",
    "    # Update the variable\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"Iteration {iter+1 :2}: x = {x.item():6.3f}, f(x) = {f_x.item():6.3f}\")\n",
    "\n",
    "\n",
    "plot_camel_back_history(hist_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assist you with the rest of experiments in this notebook, consider using the following helper function: `run_optimizer`. This function allows you to easily experiment with different optimization strategies and track the progress over multiple steps. The function allows you to optimize a given function starting from an initial point and using your choice of optimizer.\n",
    "\n",
    "```python\n",
    "def run_optimizer(func, x_init, optimizer_class, optimizer_params, n_steps):\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `func`: The function to optimize. This should be a PyTorch function that takes a 2D input (e.g., a single sample with 2 features) and returns a scalar output.\n",
    "- `x_init`: The initial value of $\\mathbf{x}$.\n",
    "- `optimizer_class`: The optimizer class you want to use (e.g., `torch.optim.SGD`, `torch.optim.Adam`).\n",
    "- `optimizer_params`: A dictionary of parameters for the optimizer (e.g., `{'lr': 0.01, 'momentum': 0.9}`).\n",
    "- `n_steps`: The number of optimization steps to run.\n",
    "\n",
    "**Returns:**\n",
    "- `hist_x`: A list containing the history of $\\mathbf{x}$ values over the optimization steps.\n",
    "- `hist_grad`: A list containing the history of gradient values over the optimization steps.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimizer(func, x_init, optimizer_class, optimizer_params, n_steps):\n",
    "    \"\"\"\n",
    "    Run the optimizer on a given function starting from an initial point.\n",
    "\n",
    "    Parameters:\n",
    "    - func: The function to optimize\n",
    "    - x_init: Initial value of x (starting point), should be a list or array-like with two elements for bivariate functions\n",
    "    - optimizer_class: The class of the optimizer (e.g., torch.optim.SGD)\n",
    "    - optimizer_params: A dictionary of parameters for the optimizer (e.g., {'lr': 0.01, 'momentum': 0.9})\n",
    "    - n_steps: Number of optimization steps\n",
    "\n",
    "    Returns:\n",
    "    - hist_x: History of x values over the optimization steps\n",
    "    - hist_grad: History of gradient values over the optimization steps\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure x_init is a tensor and keep it consistent\n",
    "    x = torch.tensor(x_init, requires_grad=True, dtype=torch.float32)\n",
    "    hist_x = [x.clone().detach().numpy()]  # Store the initial point as a numpy array\n",
    "    hist_grad = []\n",
    "\n",
    "    # Initialize the optimizer with the given parameters\n",
    "    optimizer = optimizer_class([x], **optimizer_params)\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "\n",
    "        # Pass x directly to the function\n",
    "        f_x = func(x)\n",
    "\n",
    "        f_x.backward()  # Compute the gradients\n",
    "        optimizer.step()  # Update x using the optimizer\n",
    "\n",
    "        # Record the history of x and gradients\n",
    "        hist_x.append(\n",
    "            x.clone().detach().numpy()\n",
    "        )  # Append the new x value as a numpy array\n",
    "        hist_grad.append(x.grad.clone().detach().numpy())\n",
    "\n",
    "    return hist_x, hist_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From 1D to 2D\n",
    "\n",
    "Recall that the Ackley function is a test problem for optimization algorithms. It is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "    f(x,y) = -20 \\exp \\left( -0.2 \\sqrt{0.5(x^2 + y^2)} \\right) - \\exp \\left( 0.5 \\left( \\cos(2\\pi x) + \\cos(2\\pi y) \\right) \\right) + e + 20\n",
    "\\end{equation}\n",
    "\n",
    "The Ackley function has a global minimum at $(0,0)$ with $f(0,0) = 0$.\n",
    "\n",
    "<div style=\"background-color: #3352FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "### <span style=\"color: pink;\">Task #5.</span>  Minimizing the Ackley function with SGD\n",
    "\n",
    "Use the SGD optimizer, and start from point $x_0 = (4, 3)$ to find the minimum of the Ackley function. Pick learning rate yourself and run the algorithm for 25 iterations.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ackley_func(v):\n",
    "    if type(v) == np.ndarray:\n",
    "        v = torch.tensor(v, dtype=torch.float32)\n",
    "\n",
    "    pi = torch.pi\n",
    "    x = v[0]  # Extract the x coordinates\n",
    "    y = v[1]  # Extract the y coordinates\n",
    "    x_sq = x**2\n",
    "    y_sq = y**2\n",
    "\n",
    "    # Calculate the exponential term\n",
    "    exp_term = torch.exp(-0.2 * torch.sqrt(0.5 * (x_sq + y_sq)))\n",
    "    # Calculate the cosine term\n",
    "    cos_term = torch.cos(2 * pi * x) + torch.cos(2 * pi * y)\n",
    "\n",
    "    # Compute the Ackley function value\n",
    "    f_xy = (\n",
    "        -20 * exp_term - torch.exp(0.5 * cos_term) + torch.exp(torch.tensor(1.0)) + 20\n",
    "    )\n",
    "    return f_xy\n",
    "\n",
    "\n",
    "plot_ackley()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 25\n",
    "x_init = # <--- YOUR CODE HERE \n",
    "\n",
    "\n",
    "\n",
    "optimizer4 = SGD\n",
    "optimizer_params4 = {'lr': , # <--- YOUR CODE HERE \n",
    "                     'momentum': 0.0}\n",
    "\n",
    "hist_x4, hist_grad4 = run_optimizer(# <--- YOUR CODE HERE \n",
    "\n",
    "plot_ackley(hist_x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum\n",
    "\n",
    "An extension of the SGD algorithm is the SGD with momentum. The momentum term helps accelerate the optimization process by accumulating the gradients over time. The update rule for the SGD with momentum is given by:\n",
    "\n",
    "\\begin{align}\n",
    "    m_{t+1} &= \\beta m_t + \\nabla f(x_t) \\\\\n",
    "    x_{t+1} &= x_t - \\eta m_{t+1}\\;,\n",
    "\\end{align}\n",
    "where $m_t$ is the momentum term, $\\beta$ is the momentum coefficient, and $\\eta$ is the learning rate. \n",
    "\n",
    "\n",
    "<div style=\"background-color: #3352FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "### <span style=\"color: pink;\">Task #6.</span>  Minimizing the Ackley function with SGD-Momentum\n",
    "\n",
    "Use the SGD optimizer, and start from point $x_0 = (4, 3)$ to find the minimum of the Ackley function. Pick learning rate, and the momentum coefficient yourself and run the algorithm for 25 iterations. Compare the results with the previous task.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 25\n",
    "x_init = [4.0,3.0]\n",
    "\n",
    "\n",
    "optimizer5 = SGD\n",
    "optimizer_params5 = {'lr': # <--- YOUR CODE HERE \n",
    "                     'momentum': # <--- YOUR CODE HERE \n",
    "                     }\n",
    "\n",
    "hist_x5, hist_grad5 = run_optimizer( # <--- YOUR CODE HERE \n",
    "\n",
    "plot_ackley(hist_x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Moment Estimation (Adam)\n",
    "\n",
    "An optimizer widely used in practice is the Adam optimizer. One difficulty of the SGD is adjusting its learning rate. Ideally, we would like to have a large learning rate in smooth regions (low curvature) where the gradient is small, and hence the progress is slow. Conversely, we would like to have a small learning rate in regions with high curvature, where the gradient is large. The Adam optimizer adapts the learning rate for each parameter by using the first and second moments of the gradients. The update rule (simplified for clarity) for the Adam optimizer is given by:\n",
    "\n",
    "\\begin{align}\n",
    "    m_{t+1} &= \\beta_1 m_t + (1 - \\beta_1) \\nabla f(x_t) \\\\\n",
    "    v_{t+1} &= \\beta_2 v_t + (1 - \\beta_2) \\nabla f(x_t)^2 \\\\\n",
    "    x_{t+1} &= x_t - \\eta \\frac{{m}_{t+1}}{\\sqrt{{v}_{t+1}} + \\epsilon}\\;,\n",
    "\\end{align}\n",
    "where $m_t$ and $v_t$ are the first and second moments of the gradients, respectively, $\\beta_1$ and $\\beta_2$ are the momentum coefficients, $\\eta$ is the learning rate, and $\\epsilon$ is a small constant to prevent division by zero. \n",
    "\n",
    "<div style=\"background-color: #3352FF; color: white; padding: 10px; border-radius: 5px;\">\n",
    "### <span style=\"color: pink;\">Task #7.</span>  Minimizing the Ackley function with Adam\n",
    "\n",
    "Use the Adam optimizer, and start from point $x_0 = (4, 3)$ to find the minimum of the Ackley function. Pick learning rate and run the algorithm for 25 iterations. Compare the results with the previous tasks.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 25\n",
    "x_init = [4.0,3.0]\n",
    "\n",
    "\n",
    "optimizer7 = Adam\n",
    "optimizer_params7 = {'lr': # <--- YOUR CODE HERE \n",
    "                     }\n",
    "\n",
    "hist_x7, hist_grad7 = run_optimizer # <--- YOUR CODE HERE \n",
    "\n",
    "plot_ackley(hist_x7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this notebook, we covered the key concepts related to optimization in PyTorch:\n",
    "\n",
    "- We began by understanding automatic differentiation and explored how PyTorch computes gradients.\n",
    "- We manually computed gradients for a function involving the sigmoid and entropy to better understand the backpropagation algorithm.\n",
    "- Finally, we used PyTorch’s built-in optimizers like SGD to optimize functions and analyze the impact of different hyperparameters.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
