{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"1\"> *This notebook is best viewed in jupyter lab/notebook. You may also choose to use Google Colab but some parts of the images/colouring will not be rendered properly.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# <p style=\"text-align: center;\">Lab 4 (Weeks 8,9): Convolutional Neural Networks (CNNs)</p>\n",
    "## <p style=\"text-align: center;\">Notebook II: Applications</p>\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:592/1*V6Y8FF2qfw_ztNbs1AHXNg.png\" width=\"800\" height=\"400\" />\n",
    "\n",
    "<!-- ![linear-vs-logistic-regression--medium](https://miro.medium.com/max/1400/1*dm6ZaX5fuSmuVvM4Ds-vcg.jpeg) -->\n",
    "\n",
    "Welcome to the fourth and <b>final</b> lab! As usual, this lab will span over two weeks.\n",
    "            \n",
    "In this Lab, you will find four tasks distributed across two Jupyter Notebooks: *Lab4_Basics_student.ipynb* and *Lab4_Applications_student.ipynb*. The first two tasks guide you to train a basic CNN using pytorch lightning. In the last task, you will apply the knowledge you gained to solve a practical problem.\n",
    "    \n",
    "- <b>Task 1:</b> Design a CNN and train to classify STL-10 images\n",
    "- <b>Task 2:</b> Analyse the results on the STL-10 test images\n",
    "- <b>Task 3:</b> Design and train a CNN by yourself on the FER-4 dataset and analyse results\n",
    "      \n",
    "Each task will contain code to complete, and a worded question, so ensure you complete both before submitting. Feel free to add your own additional comments.\n",
    "    \n",
    "After completion, You need to submit both Jupyter Notebooks (.ipynb files) to Moodle. Make sure all the outputs are visible before submitting.\n",
    "    \n",
    "Good luck with the final Lab! Submit it before the <b>deadline</b> to enjoy full marks.\n",
    "\n",
    "__Submission details:__\n",
    "- __Make sure you have run all your cells from top to bottom (you can click _Kernel_ and _Restart Kernel and Run All Cells_).__ </br>\n",
    "- __Submit the Jupyter Notebooks (Lab4_Basics.ipynb_) and (Lab4_Applications.ipynb_).__\n",
    "- __Outputs must be visible upon submission. We will also be re-running your code__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Enter you student details below</b>\n",
    "\n",
    "- <b>Student Name:</b> Firstname Lastname\n",
    "- <b>Student ID:</b> 123456789   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "## Table of Contents\n",
    "    \n",
    "* [Libraries](#Libraries)\n",
    "\n",
    "* [Task 3: Design and train a CNN by yourself on the FER-4 dataset and Analyse Results](#task_3)\n",
    "\n",
    "* [Discussion Questions](#t3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Libraries\n",
    "\n",
    "In this lab, you will use several pytorch and pytorch lightning libraries along with several other basic python libraries. All the libraries that you need are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.functional import log_softmax, softmax\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import transforms\n",
    "import torchmetrics\n",
    "from torchsummary import summary\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import lightning as pl ## Pytorch lightning is a wrapper for pytorch that makes it easier to train models\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.callbacks.progress import TQDMProgressBar, RichProgressBar\n",
    "from lightning.pytorch.callbacks.progress.rich_progress import RichProgressBarTheme\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "pl.seed_everything(4179)\n",
    "random.seed(4179)\n",
    "np.random.seed(4179)\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Facial Expression Recognition (FER) Dataset <a class=\"anchor\" id=\"python-basics\"></a>\n",
    "    \n",
    "For all the work in this notebook, you will be using the FER dataset.\n",
    "    \n",
    "<img src=\"https://production-media.paperswithcode.com/datasets/FER2013-0000001434-01251bb8_415HDzL.jpg\" width=\"500\" />\n",
    "    \n",
    "The FER dataset contains diverse grayscale images of 7 facial emotions classes: anger, disgust, fear, happiness, sadness, surprise, and neutrality. Each image is of size 48x48 pixels, enabling efficient processing. For simplicity, in this task you will be using a subset of the full dataset which only contains the four classes (0)happy, (1)neural, (2)sad, and (3)surprise. We will call this the **FER-4 dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Task 3 - Design and train a CNN on the FER-4 dataset and Analyse Results <a class=\"anchor\" id=\"task_3\"></a>\n",
    "        \n",
    "In this task, we do not enforce any model architecture or hyper-parameters (only some recommendations). You will design a CNN for image classification task and train it on the FER-4 dataset. You will use PyTorch's inbuilt datasets class, and Pytorch Lightning's module class to construct a CNN in order to perform training on the FER-4 dataset. You should use the knowledge obtained from Task 1 to complete this task. \n",
    "\n",
    "Note that you may want to use *transforms.Grayscale(num_output_channels = 1)* to convert the .jpg images to grayscale tensors. You will also analyse the results on the test dataset using the knowledge obtained from Task 2.\n",
    "    \n",
    "**Final deliverables of this task will be the following:**\n",
    "1. Accuracy of more than 65% on the test dataset.\n",
    "2. Reasonably converging train/val loss/accuracy curves.\n",
    "3. Confusion Matrix\n",
    "4. Visualization of top 5 misclassified images for each of the four classes.\n",
    "5. Visualization of the saliency map of a correctly predicted 'happy' image.\n",
    "6. Use an image of yourself! Capture your image from the webcam/phone and test your model.\n",
    "\n",
    "We have provided headings for where things should go, but feel free to add more to meet all the final deliverables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a quick look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# DO NOT CHANGE\n",
    "\n",
    "# Get a list of class names from the 'data/fer4/train' directory\n",
    "class_names = os.listdir('data/fer4/train')\n",
    "\n",
    "# Print the list of class names\n",
    "print(f'class names: {class_names}')\n",
    "\n",
    "# Calculate the number of classes by counting the elements in the 'class_names' list\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Print the number of classes\n",
    "print(f'number of classes: {num_classes}')\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    ???? # Convert the data to tensor\n",
    "    transforms.Grayscale(num_output_channels=1), # Transform it to a single channel grayscale image\n",
    "    ???? # Resize the image to 48x 48\n",
    "    ???? # Normalize pixel values to have a mean and standard deviation of 0.5\n",
    "])\n",
    "\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    ???? # Convert the data to tensor\n",
    "    ???? # Transform it to a single channel grayscale image\n",
    "    ???? # Resize the image to 48x 48\n",
    "    ???? # Normalize pixel values to have a mean and standard deviation of 0.5\n",
    "])\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets\n",
    "\n",
    "For this dataset, we use a different way to create the dataset. Since we already have the images ready in the folder, we will just create them using the ```torchvision.dataset.ImageFolder``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# DO NOT CHANGE\n",
    "trainset = torchvision.datasets.ImageFolder(root='data/fer4/train', transform=train_transforms)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [0.7, 0.3])\n",
    "testset = torchvision.datasets.ImageFolder(root='data/fer4/test', transform=val_test_transforms)\n",
    "\n",
    "print('Image count for each set\\n------------------------')\n",
    "print(f'trainset\\t: {len(trainset)}')\n",
    "print(f'valset  \\t: {len(valset)}')\n",
    "print(f'testset \\t: {len(testset)}')\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = ??? # Define batch size\n",
    "\n",
    "trainloader = ???\n",
    "valloader = ???\n",
    "testloader = ???\n",
    "\n",
    "print('Batch shape for each loader\\n---------------------------')\n",
    "images, labels = next(iter(trainloader))\n",
    "print(f'trainloader\\t: {images.shape}')\n",
    "images, labels = next(iter(valloader))\n",
    "print(f'valloader  \\t: {images.shape}')\n",
    "images, labels = next(iter(testloader))\n",
    "print(f'testloader \\t: {images.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the dataset\n",
    "\n",
    "Make sure you always get a feel for the dataset before you start applying models to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to visualize images from a given data loader \n",
    "# Note: Use titles to denote class label in words.\n",
    "def visualize_dataloader(dataloader, class_names):\n",
    "    \n",
    "    ???\n",
    "    \n",
    "# visualize images from the trainloader\n",
    "print('train set')\n",
    "visualize_dataloader(trainloader, class_names)\n",
    "\n",
    "# visualize images from the valloader\n",
    "print('val set')\n",
    "visualize_dataloader(valloader, class_names)\n",
    "\n",
    "# visualize images from the valloader\n",
    "print('test set')\n",
    "visualize_dataloader(testloader, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Design your own CNN\n",
    "\n",
    "Here are some guidelines in the CNN you can construct (you may stray away from this if you find other architectures are better):\n",
    "- 4 convolutional layers\n",
    "- Some (or all) of the convolutional layers can have pooling layers (this reduces size of feature maps well!)\n",
    "- Test several activation functions (ReLU, sigmoid, tanh etc.) \n",
    "- Test different optimizers (SGD usually uses lr=0.1, ADAM usually uses lr=0.001, these are only guidelines and you can tweak the learning rates based on the datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        ???\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ???\n",
    "        \n",
    "        return ???\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Define logic for training step\n",
    "        \n",
    "        ???\n",
    "        \n",
    "        return ???\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Define logic for validation step\n",
    "        ???\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Define logic for test step\n",
    "        ???\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # Define logic for inference/prediction step\n",
    "        ???\n",
    "\n",
    "        return ???\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Configure optimizers and schedulers\n",
    "        ???\n",
    "        return ???\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return valloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "task3_model = ??? # intialize CNN\n",
    "\n",
    "# print summary of the model to double check\n",
    "summary(task3_model.to('cuda'), (1, 48,48)) # delete .to('cuda') if not using cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define progress bar and checkpoint callback functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define checkpoint callback function to save the model at the best epoch\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_acc\",\n",
    "    save_top_k=1,        # save the best model based on validation accuracy\n",
    "    mode=\"max\",\n",
    "    every_n_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "task3_trainer = ??? # Call pl.Trainer and put in the relevant arguments\n",
    "\n",
    "task3_trainer.fit(task3_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the CNN\n",
    "\n",
    "For a propoer trained network, you may achieve an accuracy for at least 65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task3_trainer.test(task3_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_task_3 = ????\n",
    "metrics_task_3.set_index(\"epoch\", inplace=True)\n",
    "metrics_task_3 = metrics_task_3.groupby(level=0).sum().drop(\"step\", axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot train and validation losses against epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot train and validation accuracies against epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions for the test set for later use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are the predictions for the test set. You will use this for the tasks below during the analysis process.\n",
    "\n",
    "predictions = task3_trainer.predict(task3_model, testloader) # do not do anything to the variable 'predictions' you will reuse it\n",
    "\n",
    "test_outputs = torch.concat([prediction[0] for prediction in predictions], dim=0)\n",
    "test_labels = torch.concat([prediction[1] for prediction in predictions], dim=0)\n",
    "test_inputs = torch.concat([prediction[2] for prediction in predictions], dim=0)\n",
    "test_preds = ???? # Get the predicted lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Ensure you use **proportion** instead of absolute value. Create the confusion matrix for the four classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "# You can create a ConfusionMatrix instance for multiclass classification with 'num_classes' from the lightning library\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Misclassified\n",
    "\n",
    "You will only plot the top misclassified classes here. Please plot 5 images of each class (so 20 images in total). This will be similar to the basics notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliency Map\n",
    "\n",
    "Plot a saliency map corresponding to a happy face that was classified correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My own image\n",
    "\n",
    "Use an image of yourself being happy - hopefully you are proud of your results! Make sure you output the predicted result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in your image here (we used mpimg.imread and you just need to pass in the path to your image)\n",
    "# Feel free to use any other image reading functions instead\n",
    "img = mpimg.imread(???)[:,:,0:3]  # get rid of the 4th axis if exists\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass your image through the network\n",
    "# Remember to apply the val_test_transforms for your image before doing a forward pass of your model\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "## Discussion Questions <a class=\"anchor\" id=\"t3_1\"></a>\n",
    "    \n",
    "#### Comment on the resulting confusion matrix.\n",
    "    \n",
    "Answer: \n",
    "\n",
    "#### What was the strange thing that you observed in the actual labels when visualizing the misclassified images?\n",
    "    \n",
    "Answer: \n",
    "    \n",
    "#### Comment on the saliency map of the 'happy' image.\n",
    "    \n",
    "Answer: \n",
    "    \n",
    "#### Comment on the prediction results of your own data.\n",
    "    \n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "#### This is the end of Notebook II. Hurrah! You have now completed all the Labs for this unit! It's time to reward yourself with an assignment!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "dcb4be09c6369887b255ec43f7f14d3e527fd1b58c5c0441738eb1ab0a956e78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
