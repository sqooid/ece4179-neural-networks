{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"1\"> *This notebook is best viewed in jupyter lab/notebook. You may also choose to use Google Colab but some parts of the images/colouring will not be rendered properly.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# <p style=\"text-align: center;\">Lab 2 (Weeks 3,4): Model training with Linear Regression and Logistic Regression</p>\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg\" width=\"200\" height=\"200\" />\n",
    "\n",
    "<!-- ![linear-vs-logistic-regression--medium](https://miro.medium.com/max/1400/1*dm6ZaX5fuSmuVvM4Ds-vcg.jpeg) -->\n",
    "\n",
    "Welcome to your second lab!  Labs classes in this unit will run as a help desk and they are not mandatory to attend.\n",
    "\n",
    "This notebooks provided contain all the code and comments that you need to submit. Feel free to add in your own markdown for additional comments.\n",
    "\n",
    "Here are the instructions to complete this lab:\n",
    "\n",
    "- The marks of the lab is based on the Moodle '**Lab 2 Quiz**' attempt.\n",
    "- You need to submit the Jupyter Notebook (.ipynb file) to Moodle submission box '**Lab 2 Submission**'.\n",
    "- We do not directly mark your notebook, but it is required to show your work out for the questions.\n",
    "- If the notebook is not submitted, we consider the lab is not completed and no marks will be given for the quiz questions.\n",
    "- In some sections, we ask for screenshots of your code and plot. Please make sure to add your name and student ID to the title of the plot (which means it will also show in your code).\n",
    "- Please use the **Drop Box** in the quiz to upload images.\n",
    "- We do not require you to complete every single section in the notebook. However, for the parts that we ask for a screenshot of your code and outputs, we require those parts to be completed.\n",
    "\n",
    "This Lab has three tasks. The first two tasks test your basic knowledge regarding the linear and logistic regression and their applcations. In the last task, you will analyse the results.\n",
    "- <b>Task 1:</b> Simple linear regression\n",
    "- <b>Task 2:</b> Logistic regression and gradient descent\n",
    "- <b>Task 3:</b> Analysing convergence and accuracy\n",
    "    \n",
    "Each sub task will contain code to complete, and/or a worded question.\n",
    "\n",
    "Feel free to add in your own markdown for additional comments, and also directly comment your code.\n",
    "\n",
    "Good luck with the Lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Enter you credentials below</b>\n",
    "\n",
    "- <b>Student Name:</b> Firstname Lastname\n",
    "- <b>Student ID:</b> 123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [Task 1: Simple linear regression](#simple-linear-regression)    \n",
    "    * [1.1 Simple linear regression formulation](#lr-formulation)\n",
    "    * [1.2 Test and visualise the linear regression](#test-lr)\n",
    "    \n",
    "    \n",
    "* [Task 2: Logistic Regression and Gradient Descent](#logistic-gd)\n",
    "    * [2.1 The sigmoid function](#sigmoid)\n",
    "    * [2.2 Predicting class probabilities via logistic regression](#predict)\n",
    "    * [2.3 Training a model via Gradient Descent](#train)\n",
    "    * [2.4 Evaluating the trained model](#evaluate)\n",
    "    \n",
    "\n",
    "* [Task 3: Analysing convergence and accuracy](#analyse-convergence-and-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries, you do not need to import any additional libraries for this lab\n",
    "\n",
    "import numpy as np ## Numpy is the fundamental building block of understanding tensor (matrices) within Python\n",
    "import matplotlib.pyplot as plt ## Matplotlib.pyplot is the graphing library that we will be using throughout the semester\n",
    "import random ## Useful for sampling\n",
    "\n",
    "import os ## Useful for running command line within python\n",
    "from IPython.display import Image ## For markdown purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Before you begin\n",
    "\n",
    "We have provided some numerical answers for you to aim for. To replicate these results, do not change any of the codes that are labelled \"Do not change\".\n",
    "\n",
    "Throughout this lab, there will be code and written answers that you need to fill in / complete. The comments in the code snippet and markdown text will guide you on what you need to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Task 1 - Simple linear regression <a class=\"anchor\" id=\"simple-linear-regression\"></a>\n",
    "\n",
    "In this section, you will be writing the first parts of your code that is essential to predict the outcome of a linear regression problem. </br>\n",
    "In detail, you are going to\n",
    "- 1.1 Implement a simple linear regression function\n",
    "- 1.2 Write code to visualise the line of regression using the trained linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "## Learning Objective \n",
    "\n",
    "This task aims to understand and implement simple linear regression using the Least Squares Regression method to find the best line fit for given samples and visually analyze its performance. By the end of this task, you will be able to:\n",
    "1. Formulate a simple linear regression equation $y = wx + b$.\n",
    "2. Implement the Least Squares Regression method to find the estimated slope $\\hat{m}$ and intercept $\\hat{b}$ of the regression line, minimizing the square distances from each sample to the line.\n",
    "3. Apply the developed simple linear regression function to samples of different distributions.\n",
    "4. Visualize and analyze the performance of the linear regression model on the given samples to understand how well it fits the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Linear Regression - A quick recap\n",
    "\n",
    "Linear regression analysis is used to predict the value of a (dependent) variable based on the value of another (independent) variable assuming the there is a linear relationship between the two. Simply speaking, linear regression aims to find the best line fit for the given data. (See figure below)\n",
    "\n",
    "<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-in-machine-learning.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## 1.1 Simple linear regression formulation <a class=\"anchor\" id=\"lr-formulation\"></a>\n",
    "\n",
    "Let's consider a simple linear regression problem with one independent variable $x$ and one dependent variable $y$. The simple linear regression equation we will use is written below.\n",
    "\n",
    "$$y=wx+b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the **Least Squares Regression** to solve the problem. For a given set of data $(X,Y)$, where $X = \\{x_1, x_2, ... x_n\\}$ and $Y = \\{y_1, y_2, ... y_n\\}$, the equations are given:\n",
    "\n",
    "To estimate the slope $w$ of the regression line:\n",
    "\n",
    "$$\\hat{w}=\\frac{\\sum^{n}_{i=1}(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum^{n}_{i=1}(x_i-\\bar{x})^{2}}$$\n",
    "\n",
    "To estimate the intercept $b$ of the regression line:\n",
    "\n",
    "$$\\hat{b}=\\bar{y}-\\hat{w}\\bar{x}$$\n",
    "\n",
    "Here, $\\bar{x}$ and $\\bar{y}$ are the mean values of the data points in $X$ and $Y$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a simple linear regression function\n",
    "\n",
    "In this task, you are now first asked to write a function that takes $n$ samples in the form of $(x_i,y_i)$ as inputs and computes the slope $w$ and intercept $b$ of the regression line. (Assuming both $x$ and $y$ are 2D where the samples are on the rows and features are on columns)</br>\n",
    "\n",
    "\n",
    "The input to your function is denoted X and Y, where X is a 2D array of shape $(n,1)$ and Y is a 2D array of shape $(n,1)$ as well. The output of your function is denoted $w$ and $b$, where $w$ is the slope of the regression line and $b$ is the intercept of the regression line. \n",
    "\n",
    "_Hint_: Use the _numpy_ library you have been introduced to in the previous lab to allow easy computation of multi-dimensional input values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implement the linear regression function (Assuming both X and Y are 2D)\n",
    "\n",
    "def linear_regression(X, Y):\n",
    "    # The shape of X is (n,1), where n is the number of samples\n",
    "    # The shape of Y is (n,1), where n is the number of samples\n",
    "    X_bar = ???\n",
    "    Y_bar = ???\n",
    "    num_w = ???\n",
    "    denom_w = ???\n",
    "    w = np.array([num_w / denom_w])\n",
    "    b = Y_bar - (w*X_bar)\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## 1.2 Test and visualise the linear regression <a class=\"anchor\" id=\"test-lr\"></a>\n",
    "\n",
    "With the function you wrote in section 1.1, let's test your linear regression function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) We first load and visualise the samples.**\n",
    "\n",
    "Load the data, then select the correct range according to the quiz.\n",
    "\n",
    "Then visualise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load numpy dataset from lab2_task1_sample1.npz\n",
    "# Hint: use np.load()\n",
    "loaded_sample1 = ????\n",
    "\n",
    "# Create train and test datasets\n",
    "# Data was saved in a dictionary-liked form, where the keys are ('arr_0','arr_1')\n",
    "# Load the values into correct variables according to the following mapping.\n",
    "# (X1 <-- arr_0, Y1 <-- arr_1)\n",
    "X1 = ????\n",
    "Y1 = ????\n",
    "\n",
    "# select correct range for X1 and Y1 and reshape the new array to be proper for linear regression() function\n",
    "X1 = ????\n",
    "Y1 = ????\n",
    "\n",
    "plt.scatter(????)\n",
    "plt.title(????)\n",
    "plt.xlabel(????)\n",
    "plt.ylabel(????)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Now find parameters of the regression line with the given samples and your linear regression function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the slope and intercept of the regression line using your linear regression function on X1 and Y1\n",
    "w1, b1 = ?????\n",
    "print(w1, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Now let's try it on a different set of samples.**\n",
    "\n",
    "Load the new samples, select the correct range according to the quiz and visualise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load numpy dataset from lab2_task1_sample2.npz\n",
    "# Hit: use np.load()\n",
    "loaded_sample2 = np.load(\"lab2_task1_sample2.npz\")\n",
    "\n",
    "# Create train and test datasets\n",
    "# Data was saved in a dictionary-liked form, where the keys are ('arr_0','arr_1')\n",
    "# Load the values into correct variables according to the following mapping.\n",
    "# (X2 <-- arr_0, Y2 <-- arr_1)\n",
    "X2 = ????\n",
    "Y2 = ????\n",
    "\n",
    "# select correct range for X1 and Y1 and reshape the new array to be proper for linear regression() function\n",
    "X2 = ????\n",
    "Y2 = ????\n",
    "\n",
    "# Show samples as a scatter plot\n",
    "plt.scatter(????)\n",
    "plt.title(????)\n",
    "plt.xlabel(????)\n",
    "plt.ylabel(????)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then find the parameters of the regression line with the new samples and your linear regression function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the slope and intercept of the regression line using your linear regression function\n",
    "w2, b2 = ????\n",
    "print(w2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "#### Reflection\n",
    "\n",
    "Follow the instrctions below to make some plots that will aid you to answer the quiz question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your experience with numpy and matplotlib from the previous lab to make two plots:\n",
    "- **Plot one**: plot the data points of (X1, Y1) and the regression line from this dataset\n",
    "- **Plot two**: plot the data points of (X2, Y2) and the regression line from this dataset\n",
    "\n",
    "Visualise the regression line in the domain **$x \\in [0, 4]$.**\n",
    "\n",
    "To make the plots clearer, you can try to:\n",
    "- Visualise the regression line as a **line plot in <font color='red'>red</font> colour**.\n",
    "- Visualise the samples as a **scatter plot in <font color='blue'>blue</font> colour**.\n",
    "\n",
    "Please plot both the datapoints and the line into the same figure! </br>\n",
    "Use **50 data points** on the line to make it smooth, and make sure to add an appropriate **plot title** and to **label the axes**!</br>\n",
    "\n",
    "_Hint_: Check the matplotlib document for details how to do this. You can find many examples there for a variety of different applications. (Check the lab instructions .pdf to see an example of what is expected here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Viuslise the regression line with given samples X1 and Y1 (both on the same plot)\n",
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "# Task 2 - Logistic Regression and Gradient Descent <a class=\"anchor\" id=\"logistic-gd\"></a>\n",
    "\n",
    "In this section, you will be writing the first parts of your code that is essential to predict the outcome of a logistic regression problem. </br>\n",
    "In detail, you are going to\n",
    "\n",
    "- 2.1 Implement and visualise the **sigmoid function**\n",
    "- 2.2 Write code to **predict the outcome** of a classification problem using a pre-trained logistic regression model\n",
    "- 2.3 Train a model via Gradient Descent\n",
    "- 2.4 Evaluate the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "## Learning Objective \n",
    "\n",
    "This task aims to equip you with the knowledge and practical skills required to implement logistic regression, understand gradient descent as an optimization technique, and evaluate the performance of their trained logistic regression model on training and test datasets. By the end of this lab task, you will be able to:\n",
    "1. Implement and visualize the sigmoid function to map regression outputs into a range from 0 to 1, necessary for logistic regression.\n",
    "2. Use the sigmoid function to predict the class probabilities of a classification problem using logistic regression with a pre-trained model.\n",
    "3. Write code to perform gradient descent, compute gradients, and the cost of the logistic regression model to train it on given training data.\n",
    "4. Train their own logistic regression model using gradient descent with a fixed number of iterations.\n",
    "5. Evaluate the trained logistic regression model on previously unseen test data points.\n",
    "6. Convert class probabilities to actual predicted labels and calculate the accuracy of the model for both training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## 2.1  The sigmoid function <a class=\"anchor\" id=\"sigmoid\"></a>\n",
    "\n",
    "The '_sigmoid function_' $\\sigma$, sometimes also called '_logistic function_', is a mathematical function that shows a characteristic \"S\"-shaped curve as you've seen during the lecture (hence its name!). We commonly use this function in our logistic regression to map the regression outputs to a range from 0 to 1. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Implement the function and calculate values.**\n",
    "\n",
    "In this task, you are now first asked to write a function that computes the output of the sigmoid function $\\sigma(\\boldsymbol{x})$ for any input value $\\boldsymbol{x}$. </br>\n",
    "\n",
    "_Hint:_ Use the _numpy_ library you have been introduced to in the previous lab to allow easy computation of multi-dimensional input values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the sigmoid function\n",
    "def sigmoid(x):\n",
    "    ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) How to get both the following test cases to get True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid(????) == 0\n",
    "\n",
    "sigmoid(????) == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Adjust range and Visualize the function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the c1 and c2 values in the Quiz question, adjust the output range of the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = ????\n",
    "c2 = ????\n",
    "\n",
    "# check the sigmoid range\n",
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Then now use your experience with numpy and matplotlib from the previous lab to visualise the output range of our **adjusted** sigmoid function for a 1 dimensional case in the domain $x \\in [-10, 10]$. </br>\n",
    "\n",
    "In detail, we ask you to:\n",
    "- Visualise the outputs of  f(x) =  c1 sigmoid(x) + c2  as a **line plot in <font color='blue'>blue</font> colour**.\n",
    "- Visualise the outputs of  f(x) =  c1 sigmoid(x) + c2  as a **scatter plot in <font color='red'>red</font> colour**.\n",
    "\n",
    "Please plot both into the same figure! </br>\n",
    "\n",
    "Use **50 data points** to get a smooth plot, and make sure to add an appropriate **plot title** and to **label the axes**!</br>\n",
    "\n",
    "Please add your name and Student ID to the title of the plot.\n",
    "\n",
    "_Hint_: Check the matplotlib docu for details how to do this. You can find many examples there for a variety of different applications. (Check the lab instructions .pdf to see an example of what is expected here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualise the adjusted output \n",
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then now use your experience with numpy and matplotlib from the previous lab to visualise the output range of our **adjusted** sigmoid function for a 1 dimensional case in the domain $x \\in [-10, 10]$. </br>\n",
    "\n",
    "In detail, we ask you to:\n",
    "- Visualise the outputs of the sigmoid as a **line plot in <font color='blue'>blue</font> colour**.\n",
    "- Visualise the outputs of the sigmoid as a **scatter plot in <font color='red'>red</font> colour**.\n",
    "\n",
    "Please plot both into the same figure! </br>\n",
    "\n",
    "Use **50 data points** to get a smooth plot, and make sure to add an appropriate **plot title** and to **label the axes**!</br>\n",
    "\n",
    "Please add your name and Student ID to the title of the plot.\n",
    "\n",
    "_Hint_: Check the matplotlib document for details how to do this. You can find many examples there for a variety of different applications. (Check the lab instructions .pdf to see an example of what is expected here.)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Make sure the graph is something like the one below. Otherwise an incorrect sigmoid function will effect your results later on.\n",
    "\n",
    "![sigmoid](./figs/sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## 2.2 Predicting class probabilities via logistic regression <a class=\"anchor\" id=\"predict\"></a>\n",
    "\n",
    "You will now use your implemented sigmoid function to solve an actual classification problem using logistic regression. </br>\n",
    "As discussed in the lecture, a prediction $\\hat{y}$ can be obtained by using our logistic regression model via $\\hat{y}=\\sigma(\\boldsymbol{w}^\\top \\boldsymbol{x})$\n",
    "\n",
    "Note that for this example, we want to be able to use many samples at the same time - all of which are stored in one single vector $X$, which is similar to the test case $\\boldsymbol{x_3}$ from before.\n",
    "\n",
    "Also note that we predict the distribution over the classes, _i.e._ the probablity for each class -> to get the 'hard' class label, we will later on assign everything below the probablity of 0.5 to class1 and any probability above to class2 (boundary could be included in either)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Load the dataset, inspect it, and fill the blanks in the Quiz Question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the lab2_task2_data.npz using numpy --> data has been saved via np.savez (check docu for more details)\n",
    "\n",
    "# Components can be accessed like a dictionary after the file has been loaded, and the file contains the following:\n",
    "# 'X_train' : training data we're going to use\n",
    "# 'y_train' : labels for the training data\n",
    "# 'X_test'  : test data we're going to use for evaluation, but NOT for training\n",
    "# 'y_test'  : labels for the test data\n",
    "# 'w_pret'  : a set of pretrained weights for the logistic regression model\n",
    "\n",
    "loaded_data = ????\n",
    "X_train = ????\n",
    "y_train = ????\n",
    "X_test = ????\n",
    "y_test = ????\n",
    "w_pret = ????\n",
    "## Check the shape of the data!\n",
    "# Note that we assume certain shapes of data for the basic logistic regression formulas to work,\n",
    "# so make sure you understand which elements should be multiplied with each other!\n",
    "# Hint: In case the data is stored in a different shape, you can easily transpose the matrices!\n",
    "\n",
    "\n",
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Add side by side plots here to visualise your train and test data (Use subplots).**\n",
    "\n",
    "Here you need to visulize the second input variable w.r.t the first one and then color the points by their label.\n",
    "\n",
    "You may find **scatter plot** suitable, and your plots should be something like this one given below (points are random here):\n",
    "\n",
    "![rand_data](./figs/rand_data.png)\n",
    "\n",
    "**Reminder**: Please add axes labels, and have your name and ID in the title of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add side by side plots here to visualise your train and test data (Use subplots).\n",
    "# These are the two classes that you will be classifying.\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = ????\n",
    "\n",
    "ax1.????  #Plot train set\n",
    "????      #Set proper title \n",
    "????      #Set axis labels\n",
    "????      #Set title\n",
    "\n",
    "\n",
    "ax2.????  #Plot test set\n",
    "????      #Set proper title \n",
    "????      #Set axis labels\n",
    "????      #Set title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Implement a logistic regression model**\n",
    "\n",
    "You are now going to\n",
    "- Implement a function to predict outcomes using a logistic regression model (taking in data $\\boldsymbol{X}$ and parameters $\\boldsymbol{w}$)\n",
    "- Please note that the parameters $\\boldsymbol{w}$ of shape $(\\# input \\, features , 1) $ and  $\\boldsymbol{X}$ of size $(\\# samples, \\# input \\, features)$  are passed as input arguments to your function and it should provide $\\hat{y}$ (the probability) of size $(\\# samples, 1)$ in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a prediction function -> We predict the output class probability, NOT the class label (no 0,1 rounding)\n",
    "\n",
    "def predict(X, w):\n",
    "\n",
    "    # Input argument(s):\n",
    "    # X - the input data\n",
    "    # w - the weights from the trained model\n",
    "     \n",
    "    # Output:\n",
    "    # Probability prediction of each data point (y_hat)\n",
    "\n",
    "    # pass input data to x\n",
    "    x =????   \n",
    "\n",
    "    # Perform Matrix multiplication between the inputs and the weights\n",
    "    z = ????\n",
    "\n",
    "    # probability\n",
    "    y_hat = ????\n",
    "\n",
    "    return y_hat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Test your prediction function using the toy data set given in the quiz**\n",
    "\n",
    "You can find the datapoints in the Quiz Question\n",
    "\n",
    "Note define the toy data [number of samples, dim].\n",
    "\n",
    "We also want the same to be true for our predictions, _i.e._ return them in the shape of [number of samples, 1] to match the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the toy input data\n",
    "\n",
    "X_toy = ????\n",
    "\n",
    "## Obtain predictions using predict function and pretrained parameters w_pret\n",
    "y_hat_toy = ????\n",
    "\n",
    "print(f'y_hat_toy_sum: {?????}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## 2.3 Training a model via Gradient Descent <a class=\"anchor\" id=\"train\"></a>\n",
    "    \n",
    "In this task, you will be writing code for the essential components to **train your own logistic model via Gradient Descent** given some training data. </br>\n",
    "In detail, you are going to\n",
    "- Implement a function that computes and returns **gradient and cost** of the logistic regression\n",
    "- Write code to perform the actual **gradient descent algorithm** for a fixed number of iterations and **train your own logistic regression model** given some training data\n",
    "- **Evaluate your model** on previously unseen test data points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in more detail during the lecture, we commonly use the so-called _Cross Entropy_ Loss to calculate the cost of our logistic regression problem. This loss function can be defined as </br>\n",
    "</br>\n",
    "\\begin{equation}\n",
    "    \\mathcal{L}_{\\mathrm{CE}}(\\boldsymbol{w})= - \\frac{1}{m}\\sum_{i=1}^{m} \\Big\\lbrace y_i \\log \\Big(\\underbrace{\\sigma\\left(\\boldsymbol{w}^\\top \\boldsymbol{x}_i\\right)}_{\\hat{y}_i}\\Big) + \\left( 1 - y_i \\right) \\log \\Big( 1- \\underbrace{\\sigma\\left(\\boldsymbol{w}^\\top \\boldsymbol{x}_i\\right)}_{\\hat{y}_i}\\Big) \\Big\\rbrace\n",
    "\\end{equation}\n",
    "</br>\n",
    "In this notation, $\\sigma(z) = 1 / (1 + \\exp(-z))$ denotes the **sigmoid** function, and $(\\boldsymbol{x}_1,y_1),(\\boldsymbol{x}_2,y_2),\\dots,(\\boldsymbol{x}_m,y_m)$ with $\\boldsymbol{x}_i \\in \\mathbb{R}^n, y_i \\in \\lbrace 0, 1\\rbrace$ represent the $m$ training samples (with labels $y_i$). </br>\n",
    "The gradient of the cross entropy loss w.r.t. the weights $\\boldsymbol{w}$ can be written as\n",
    "</br>\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nabla_{\\boldsymbol{w}}\\mathcal{L}_{\\mathrm{CE}} = \\frac{1}{m}\\sum_{i=1}^{m} \\Big(\\underbrace{\\sigma\\left(\\boldsymbol{w}^\\top \\boldsymbol{x}_i\\right)}_{\\hat{y}_i} - y_i \\Big) \\boldsymbol{x}_i\n",
    "\\end{equation}\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gradient and Cost Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Implemnt the function**\n",
    "\n",
    "In this part, we want to define a function that is able to compute our cross-entropy loss $\\mathcal{L}_{\\mathrm{CE}}$, as well as the gradient $\\nabla_{\\boldsymbol{w}}\\mathcal{L}_{\\mathrm{CE}}$ of our loss $\\mathcal{L}_{\\mathrm{CE}}$ _w.r.t._ the parameters $\\boldsymbol{w}$, we want $\\nabla_{\\boldsymbol{w}}\\mathcal{L}_{\\mathrm{CE}}$ to be return of shape $(1,\\# parameters)$. \n",
    "\n",
    "As you can see above, all we need to compute the gradient vector is the prediction of the model $\\hat{y}$ and the actual labels $y$, as well as the input data points $\\boldsymbol{X}$. The loss itself is even more simple and only requires the predictions $\\hat{y}$ and true labels $y$.\n",
    "\n",
    "In the following function for the simplicity try to code $a$ and $b$, then create $\\mathcal{L}_{\\mathrm{CE}}$ loss out of them.\n",
    "</br>\n",
    "\\begin{equation}\n",
    "    \\mathcal{L}_{\\mathrm{CE}}(\\boldsymbol{w})= - \\frac{1}{m}\\sum_{i=1}^{m} \\Big\\lbrace \\underbrace{ y_i \\log \\Big(\\underbrace{\\sigma\\left(\\boldsymbol{w}^\\top \\boldsymbol{x}_i\\right)}_{\\hat{y}_i}\\Big)}_{a} + \\underbrace{\\left( 1 - y_i \\right) \\log \\Big( 1- \\underbrace{\\sigma\\left(\\boldsymbol{w}^\\top \\boldsymbol{x}_i\\right)}_{\\hat{y}_i}\\Big)}_{b} \\Big\\rbrace\n",
    "\\end{equation}\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_and_grad(X, y, y_hat):\n",
    "    # Inputs:\n",
    "    #    X - Set of samples (each sample is a row in X),\n",
    "    #    y - Corresponding ground-truth labels\n",
    "    #    y_hat - Predicted class probabilities\n",
    "\n",
    "    # log(0) might throw error, so handled via small eps \n",
    "    eps = 1e-12\n",
    "\n",
    "    # Compute the mean cross-entropy loss w.r.t. the parameters w (mean as defined in lecture)\n",
    "    a = ????\n",
    "    b = ????\n",
    "    loss = np.mean(-(a + b))\n",
    "\n",
    "    # Compute the gradient vector (mean over all samples as defined in lecture)\n",
    "    grad_vec = ????\n",
    "    \n",
    "\n",
    "    # Return loss and gradient vector\n",
    "    return loss, grad_vec, grad_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Apply the function**\n",
    "\n",
    "Pass the datapoints given in the Quiz Question through the function you just implemented, and printout the loss, gradient and the shape of the gradient vector.\n",
    "\n",
    "Your **full name** must be printed in the first line before the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Student_name = ????\n",
    "X_toy = ????\n",
    "y_toy = ????\n",
    "y_hat_toy = ????\n",
    "\n",
    "loss, grad_vec, grad_vec_shape =????\n",
    "\n",
    "# Also print your name or ID here\n",
    "print(f'Student : {Student_name}')\n",
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Training with Gradient Descent**\n",
    "\n",
    "Gradient descent, sometimes also referred to as _steepest descent_, is a popular first-order iterative optimisation method that has become ubiquitous in the machine and deep learning context. As you have heard in the lecture, the idea is to find the local minimum of a differentiable function by repeatedly taking steps in the opposite direction of the gradient of the function at the current point - i.e. in the direction of its steepest descent.\n",
    "\n",
    "In this section of the lab, you are going to implement the **Gradient Descent algorithm** as a function that we can use afterwards to train our logistic regression model!\n",
    "\n",
    "The main parts of the algorithm work as follows:\n",
    "- Initialise hyperparameters like step-size aka learning rate, and number of iterations\n",
    "- Randomly initialise the set of parameters $\\boldsymbol{w}_{init}$ that shall be optimised\n",
    "- For a certain number of iterations, do:\n",
    "    - Obtain the prediction using the current weights $\\boldsymbol{w}_i$ and training data $\\boldsymbol{X}_{train}$\n",
    "    - Compute the loss $\\mathcal{L}_{\\mathrm{CE}}$ and the gradient vector $\\nabla_{\\boldsymbol{w}}\\mathcal{L}_{\\mathrm{CE}}$ w.r.t. the current parameters $\\boldsymbol{w}_i$\n",
    "    - Update the parameters using the gradient vector and learning rate _lr_\n",
    "- After all iterations are finished, return the final optimised set of parameters\n",
    "\n",
    "In addition, we ask you to also:\n",
    "- Return a list of all losses (one value for each iteration)\n",
    "- Return a list of all gradient vectors (one vector for each iteration)\n",
    "- Implement an option via the argument \"logging\" to switch on printing a string containing the 'iteration' and the 'loss' for each iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very Important:**\n",
    "Note that the inputs to this function are:\n",
    "- initial set of parameters $\\boldsymbol{w}_{init}$ of shape $(\\# input \\, features, 1) $\n",
    "- the hyperparameters #epochs and learning rate\n",
    "- the training data $\\boldsymbol{X}_{train}$ of shape $(\\# samples, \\# input \\, features)$ \n",
    "- the corresponding labels $\\boldsymbol{y}_{train}$ of shape $(\\# samples, 1)$ \n",
    "\n",
    "and the outputs should be \n",
    "- a list of all losses \n",
    "- a list of all gradient vetors and each gradient vector must be of shape $(1, \\# input \\, features) $\n",
    "- the final weight $\\boldsymbol{w}^{*}$ of shape $(\\# input \\, features, 1) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting some hyperparameters:\n",
    "lr = 0.5         # Learning rate\n",
    "num_epochs = 20    # Number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(w_init, num_epochs, lr, X_train, y_train, logging=False):\n",
    "    ## Create empty lists to store the values for loss and gradient vector over all\n",
    "    #  'num_epochs' iterations of our gradient descent optimisation procedure\n",
    "    losses = []\n",
    "    grad_vecs = []\n",
    "\n",
    "    # Init the parameters\n",
    "    w = w_init\n",
    "\n",
    "    ## Implement the actual gradient descent using the previously implemented functions\n",
    "    for ep in range(num_epochs):\n",
    "        # Compute prediction using current weights\n",
    "        preds =  ?????\n",
    "        loss, grad_vec, grad_vec_shape = compute_loss_and_grad(X_train, y_train, preds) \n",
    "        w = w - ?????\n",
    "\n",
    "        losses.?????\n",
    "        grad_vecs.?????\n",
    "\n",
    "        if logging:\n",
    "            print(f'Ep {ep+1:2d} | Loss: {loss:.3f}')\n",
    "\n",
    "    return w, losses, grad_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Now training time!**\n",
    "\n",
    "Use the initial weights given in the Quiz Question, and run the gradient descent algorithm for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the function on the training set\n",
    "## Start from given initial weight in teh quiz\n",
    "w_init = ?????\n",
    "\n",
    "# Obtain the final weights via gradient descent\n",
    "w_final, _, _ = ?????\n",
    "print(w_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Create a new function as gradient_descent_ver2() that takes same input**\n",
    "- and provides same output plus:\n",
    "- a list of all values for the first (i.e. $w_1$) and second (i.e. $w_2$) parameters $w = [w_1 \\, w_2]^T$.\n",
    "\n",
    "Apply this function and start from given $w_{init}$ in Task 2.3 (d) of the quiz and visualize how these parameters converge w.r.t the epochs. (Two plots for two parameters)\n",
    "\n",
    "Then add the loss convergence.\n",
    "\n",
    "\n",
    "Reminder: You should have three plots in one column showing the convergence of $w_1$, $w_2$, and  $\\mathcal{L}_{\\mathrm{CE}}$ w.r.t. epochs. Please add your name and Student ID to the title of at least one plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_ver2(w_init, num_epochs, lr, X_train, y_train, logging=False):\n",
    "    \n",
    "    ?????\n",
    "\n",
    "    return w, losses, grad_vecs, w_1_values, w_2_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the function on the training set\n",
    "\n",
    "## Start from given initial weight in teh quiz\n",
    "w_init = ?????\n",
    "_, losses, _ , w_1_values, w_2_values= gradient_descent_ver2( ?????)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = ?????\n",
    "epochs = range(num_epochs)\n",
    "\n",
    "ax1.?????\n",
    "\n",
    "ax2.?????\n",
    "\n",
    "ax3.?????\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## 2.4 Evaluating the trained model <a class=\"anchor\" id=\"evaluate\"></a>\n",
    "\n",
    "After you have obtained your optimised set of parameters $\\boldsymbol{w}^{*}$, let's see how your model performs! </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) To this end, you are going to do the following**\n",
    "\n",
    "- Obtain the predictions (class probabilities) $\\hat{y}_{train}$ for the training data $\\boldsymbol{X}_{train}$ using $\\boldsymbol{w}^{*}$\n",
    "- Obtain the predictions (class probabilities) $\\hat{y}_{test}$ for the test data $\\boldsymbol{X}_{test}$ using $\\boldsymbol{w}^{*}$\n",
    "- Convert these into the actual predicted labels (everything with probability >=0.5 is more likely to be of class 1 and thus gets label '1' assigned ; below gets label '0')\n",
    "- Count how many samples have been correctly classified and compute the percentage (_i.e._, the accuracy in %)\n",
    "- Report your obtained accuracies for both training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate the obtained model on previously unseen test data\n",
    "\n",
    "# Obtain predicted class probabilities for test data\n",
    "y_hat_test  = predict(?????, w_final)\n",
    "\n",
    "# Obtain class labels\n",
    "c_hat_test = ????? (?????)\n",
    "\n",
    "\n",
    "# Evaluate the classification accuracy\n",
    "acc_test = ?????/ ?????\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Print out train and test accuracy if you start training from the given initial weight in the quiz Task 2.4(b)**\n",
    "\n",
    "- You should repeat gradient decsent starting from the $w_{init}$ and obtain $w^{*}$\n",
    "- Then calculate the accuracy on test and train set for the model with weights $w^{*}$\n",
    "- print the accuracy for both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeat training model from given initial weight in the quiz\n",
    "w_init = ????\n",
    "w_final ?????\n",
    "\n",
    "\n",
    "# Obtain predicted class probabilities for train and test data\n",
    "???????\n",
    "\n",
    "# Obtain actual class labels for training and test data\n",
    "???????\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the classification accuracy for training and test data\n",
    "acc_train = ???????\n",
    "acc_test= ???????\n",
    "\n",
    "\n",
    "# Print outputs\n",
    "print(f'Training accuracy: {acc_train:.3f}')\n",
    "print(f'Test accuracy: {acc_test:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "#### Reflection\n",
    "\n",
    "Based on the Code tasks you have done, select the incorrect statement from the given list in the quiz.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Task 3 - Analysing convergence and accuracy <a class=\"anchor\" id=\"analyse-convergence-and-accuracy\"></a>\n",
    "    \n",
    "In this section, your task involves examining logistic regression models using various hyper-parameter configurations and assessing their convergence behavior.  </br>\n",
    "In detail, you are going to\n",
    "\n",
    "## Improving the accuracy <a class=\"anchor\" id=\"improve-accuracy\"></a>\n",
    "Our previous choice of hyperparameters might not be the best possible one (or even close to it). </br>\n",
    "Can you achieve a **better test accuracy** by changing the hyperparameters from the previous task? </br>\n",
    "Try to improve upon the standard choice by varying the learning rate `lr`. At the meantime, we are going to take a closer look at how gradient descent 'progresses' for different choices of learning rate. Report your choice and best results below!\n",
    "\n",
    "Given the provided set of learning rates _lrs_, run your implemented gradient descent method and plot the obtained loss values over the number of iterations for each learning rate.  </br>\n",
    "Additionally save the training and test accuracies achieved for each learning rate. </br>\n",
    "You can re-use/copy-and-paste your code from above, or define it as a function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "## Learning Objective \n",
    "The aim of this task is to enhance learners' ability to fine-tune hyperparameters for logistic regression models, interpret convergence trends, and make informed decisions about model accuracy and potential overfitting on the dataset. By the end of this lab task, the you will be able to:\n",
    "1. Analyze and compare the test accuracy of the logistic regression model with different hyperparameter settings.\n",
    "2. Evaluate the training convergence of the logistic regression model during the training process and identify any general trends in the convergence behavior.\n",
    "3. Assess whether the model shows signs of overfitting on the given dataset by analyzing the training vs. test accuracy.\n",
    "4. Describe their observations regarding the relationship between the choice of learning rates, convergence results, and accuracy on the training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Try different learning rates**\n",
    "\n",
    "- A list of learning rates are given in the quiz\n",
    "- The number of training epochs is also given.\n",
    "- You should repeat training the model for all learning rates given in the list (hint: use a $for$ loop)\n",
    "- The initial weight is fixed for all the training scenarios  $w_{init} = [-2 \\quad 2]^T$\n",
    "- Then visualize the lossed of each training w.r.t. epochs for all given learning rates in the list in one graph. \n",
    "- Each loss plot must have a legend of corresponding learning rate. \n",
    "- Please add your name and Student ID to the title of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provided list of learning rates to train on:\n",
    "lrs = ????\n",
    "# Max number of iterations for GD algorithm to run\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Fix the initial point\n",
    "w_init = np.array([[-2] , [2]])\n",
    "# ================================================\n",
    "\n",
    "## Run gradient descent for all learning rates, and plot results\n",
    "??????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Fill the blanks in the Quiz Question, based on your analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Write evaluate() function that takes input $X$, output $y$, and the final weight $w^*$ and calculates accuracy.**\n",
    "\n",
    "- A list of learning rates is given in the quiz.\n",
    "- Repeat training the model by all the given learning rates (hit: use a $for$ loop)\n",
    "- Record the final weight $w^*$ for all traning scenarios.\n",
    "- Then apply the evaluate() function to camculate the accuracy of different models you have trained by given learning rates.\n",
    "- Print the test and train accuracy next to the corresponding learning rate. \n",
    "- Print your name and ID in the first line of the output.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Provided list of learning rates to train on:\n",
    "lrs = ?????\n",
    "# Max number of iterations for GD algorithm to run\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Fix the initial point\n",
    "w_init = np.array([[-2] , [2]])\n",
    "# ================================================\n",
    "\n",
    "## Run gradient descent for all learning rates, and keep the w_finals\n",
    "?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the stored parameter sets to retrieve train and test accuracies\n",
    "def evaluate(X,y,w):\n",
    "    # Obtain predicted class probabilities\n",
    "    y_hat = ?????\n",
    "\n",
    "    # Obtain actual class labels (everything >=0.5 is class1, rest class0)\n",
    "    c_hat = ?????\n",
    "\n",
    "    # Evaluate the classification accuracy for training and test data\n",
    "    acc = ?????\n",
    "    return acc\n",
    "\n",
    "print(\"Student :  ????? \")\n",
    "\n",
    "print(' >>> Training accuracies for different learning rates: <<<')\n",
    " ?????\n",
    "\n",
    "print('\\n >>> Test accuracies for different learning rates: <<<')\n",
    " ?????\n",
    "\n",
    "print(\"Model trained by. ????? is the best model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "# <p style=\"text-align: center;\">The End</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
